{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a65c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de80b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aa2bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4515cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05e3bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffaaf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the capital of France?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df5c2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6adec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfcacd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector=embedding_model.embed_query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07d82b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04257791489362717,\n",
       " -0.047810737043619156,\n",
       " -0.02702580951154232,\n",
       " -0.035097863525152206,\n",
       " 0.05324113741517067,\n",
       " 0.0018493696115911007,\n",
       " 0.004823467694222927,\n",
       " -0.022051338106393814,\n",
       " 0.0009697225177660584,\n",
       " 0.07324519753456116,\n",
       " -0.014812891371548176,\n",
       " 0.003644853364676237,\n",
       " -0.00034491211408749223,\n",
       " 0.028128888458013535,\n",
       " 0.025020018219947815,\n",
       " -0.04156218096613884,\n",
       " 0.005471833515912294,\n",
       " 0.02652869001030922,\n",
       " 0.043672770261764526,\n",
       " -0.014782802201807499,\n",
       " 0.013127882033586502,\n",
       " 0.007567551918327808,\n",
       " -0.03469207510352135,\n",
       " 0.023462051525712013,\n",
       " 0.020962651818990707,\n",
       " -0.05559537559747696,\n",
       " 0.00859882216900587,\n",
       " -0.04824773594737053,\n",
       " -0.012368501164019108,\n",
       " -0.001532181748189032,\n",
       " -0.07255345582962036,\n",
       " 0.04269229248166084,\n",
       " 0.00527808116748929,\n",
       " -0.015593086369335651,\n",
       " 0.02645784802734852,\n",
       " -0.0531519278883934,\n",
       " -0.0004922056687064469,\n",
       " 0.016876710578799248,\n",
       " -0.00814562477171421,\n",
       " 0.04225021228194237,\n",
       " -0.015036126598715782,\n",
       " -0.003916633781045675,\n",
       " -0.04687097668647766,\n",
       " 0.015219401568174362,\n",
       " -0.009408559650182724,\n",
       " -0.01825689896941185,\n",
       " -0.01993844285607338,\n",
       " 0.0748581662774086,\n",
       " 0.019254358485341072,\n",
       " -0.0052777305245399475,\n",
       " 0.012134595774114132,\n",
       " -0.010617725551128387,\n",
       " 0.054592013359069824,\n",
       " 0.020773116499185562,\n",
       " 0.013602628372609615,\n",
       " -0.06971295922994614,\n",
       " 0.008997276425361633,\n",
       " -0.014119189232587814,\n",
       " -0.0046128276735544205,\n",
       " 0.0210944302380085,\n",
       " 0.0329081267118454,\n",
       " -0.030065499246120453,\n",
       " 0.00447330716997385,\n",
       " 0.0407467782497406,\n",
       " 0.01971225067973137,\n",
       " -0.055106159299612045,\n",
       " 0.03556030988693237,\n",
       " 0.013304406777024269,\n",
       " 0.08534496277570724,\n",
       " 0.00158949033357203,\n",
       " -0.004593267105519772,\n",
       " -0.042083490639925,\n",
       " 0.0713706836104393,\n",
       " 0.005657872185111046,\n",
       " 0.030689362436532974,\n",
       " -0.0817095935344696,\n",
       " -0.02232016995549202,\n",
       " 0.06454379111528397,\n",
       " 0.01360271591693163,\n",
       " -0.04246792569756508,\n",
       " -0.00804409384727478,\n",
       " -0.05186443775892258,\n",
       " -0.07956809550523758,\n",
       " -0.02714453637599945,\n",
       " -0.05819103121757507,\n",
       " 0.014083041809499264,\n",
       " -0.05621412768959999,\n",
       " -0.018843192607164383,\n",
       " -0.05411393195390701,\n",
       " 0.04985203966498375,\n",
       " -0.025272108614444733,\n",
       " 0.006586411036550999,\n",
       " 0.07480309158563614,\n",
       " -0.040020957589149475,\n",
       " -0.028987407684326172,\n",
       " 0.06478418409824371,\n",
       " -0.014494857750833035,\n",
       " -0.011784432455897331,\n",
       " 0.07746846228837967,\n",
       " -0.003581888973712921,\n",
       " 0.01965465024113655,\n",
       " -0.021930739283561707,\n",
       " -0.07060352712869644,\n",
       " 0.05417868122458458,\n",
       " 0.03164941444993019,\n",
       " -0.00866173766553402,\n",
       " -0.01214554999023676,\n",
       " 0.058456458151340485,\n",
       " 0.006299072410911322,\n",
       " 0.06679613888263702,\n",
       " -0.0667213425040245,\n",
       " -0.04552998021245003,\n",
       " 0.031006908044219017,\n",
       " 0.06095348298549652,\n",
       " 0.01496248971670866,\n",
       " -0.05309277027845383,\n",
       " -0.03518706187605858,\n",
       " 0.017601503059267998,\n",
       " 0.03776673972606659,\n",
       " 0.024583736434578896,\n",
       " 0.035969726741313934,\n",
       " -0.018826857209205627,\n",
       " 0.044718313962221146,\n",
       " -0.045678626745939255,\n",
       " 0.034775298088788986,\n",
       " -0.01982470043003559,\n",
       " -0.04870112985372543,\n",
       " 0.032311610877513885,\n",
       " -0.011565012857317924,\n",
       " 0.021644998341798782,\n",
       " 0.015746233984827995,\n",
       " -0.04829183965921402,\n",
       " -0.014721618965268135,\n",
       " -0.002236217027530074,\n",
       " 0.014409353025257587,\n",
       " 0.030544603243470192,\n",
       " 0.061715949326753616,\n",
       " -0.018756143748760223,\n",
       " 0.04099138453602791,\n",
       " 0.006017507519572973,\n",
       " 0.029441386461257935,\n",
       " 0.0671597346663475,\n",
       " 0.0025576308835297823,\n",
       " 0.028602181002497673,\n",
       " -0.018605684861540794,\n",
       " 0.05013180524110794,\n",
       " -0.0542902871966362,\n",
       " -0.03664889186620712,\n",
       " 0.040750712156295776,\n",
       " -0.044509004801511765,\n",
       " -0.07576945424079895,\n",
       " 0.0016938719199970365,\n",
       " -0.04662192612886429,\n",
       " -0.02760942094027996,\n",
       " 0.0392257384955883,\n",
       " 0.010924643836915493,\n",
       " -0.0143031757324934,\n",
       " 0.048677846789360046,\n",
       " 0.01945548690855503,\n",
       " -0.0165046788752079,\n",
       " 0.05750593915581703,\n",
       " 0.017886588349938393,\n",
       " 0.016367116943001747,\n",
       " 0.006838107947260141,\n",
       " -0.0027852400671690702,\n",
       " -0.028113022446632385,\n",
       " 0.03293533995747566,\n",
       " -0.008162261918187141,\n",
       " 0.016503559425473213,\n",
       " -0.0008890617173165083,\n",
       " -0.011331772431731224,\n",
       " 0.01560590323060751,\n",
       " -0.002747876103967428,\n",
       " -0.023822380229830742,\n",
       " 0.008317090570926666,\n",
       " -0.033890966325998306,\n",
       " 0.011247474700212479,\n",
       " -0.02326224185526371,\n",
       " -0.014204729348421097,\n",
       " -0.031394872814416885,\n",
       " 0.006071117240935564,\n",
       " -0.03975209593772888,\n",
       " 0.006350292824208736,\n",
       " 0.03685023635625839,\n",
       " 0.011773370206356049,\n",
       " -0.043271128088235855,\n",
       " 0.022107595577836037,\n",
       " -0.03222227841615677,\n",
       " 0.004633280448615551,\n",
       " 0.01861286163330078,\n",
       " -0.0461781807243824,\n",
       " -0.013411097228527069,\n",
       " -0.014593689702451229,\n",
       " -0.017189396545290947,\n",
       " -0.037615299224853516,\n",
       " -0.01175762340426445,\n",
       " 0.029062220826745033,\n",
       " -0.017437946051359177,\n",
       " 0.0454525351524353,\n",
       " -0.05209745094180107,\n",
       " -0.029428549110889435,\n",
       " 0.03321756049990654,\n",
       " 0.02435440942645073,\n",
       " -0.0358048640191555,\n",
       " 0.022126683965325356,\n",
       " -0.00966416671872139,\n",
       " 0.08779031038284302,\n",
       " -0.03464784100651741,\n",
       " -0.043734170496463776,\n",
       " 0.05736429989337921,\n",
       " -0.014013061299920082,\n",
       " 0.006000404711812735,\n",
       " -0.02421995811164379,\n",
       " 0.016350895166397095,\n",
       " 0.044808026403188705,\n",
       " -0.025562455877661705,\n",
       " 0.07690118998289108,\n",
       " 0.010970678180456161,\n",
       " 0.04207293689250946,\n",
       " -0.022715603932738304,\n",
       " -0.04467586800456047,\n",
       " -0.003055560402572155,\n",
       " -0.023600663989782333,\n",
       " -0.013115497305989265,\n",
       " 0.04398322477936745,\n",
       " 0.023938285186886787,\n",
       " -0.011075073853135109,\n",
       " -0.03778417780995369,\n",
       " 0.00021477344853337854,\n",
       " -0.010648282244801521,\n",
       " -0.05003296211361885,\n",
       " 0.07658620178699493,\n",
       " 0.03315397724509239,\n",
       " -0.02210102789103985,\n",
       " 0.05767066404223442,\n",
       " 0.0006767681916244328,\n",
       " -0.003242972306907177,\n",
       " 0.020267846062779427,\n",
       " 0.0006321387481875718,\n",
       " 0.0009972446132451296,\n",
       " -0.02512633241713047,\n",
       " -0.03888467326760292,\n",
       " 0.04662318155169487,\n",
       " 0.023061562329530716,\n",
       " -0.04041805863380432,\n",
       " -0.038651108741760254,\n",
       " -0.027900371700525284,\n",
       " 0.024071509018540382,\n",
       " 0.05060867220163345,\n",
       " 0.05143703520298004,\n",
       " -0.002084001898765564,\n",
       " 0.0024474747478961945,\n",
       " 0.032136015594005585,\n",
       " 0.019393740221858025,\n",
       " -0.07943607866764069,\n",
       " 0.02427038736641407,\n",
       " -0.06520397216081619,\n",
       " 0.031165381893515587,\n",
       " -0.035928234457969666,\n",
       " 0.03409767523407936,\n",
       " 0.030861197039484978,\n",
       " 0.03538651764392853,\n",
       " 0.042785514146089554,\n",
       " -0.03435273468494415,\n",
       " -0.015017978847026825,\n",
       " -0.03510842099785805,\n",
       " 0.006179507356137037,\n",
       " -0.05111760273575783,\n",
       " 0.012249006889760494,\n",
       " 0.005350593011826277,\n",
       " 0.03790914639830589,\n",
       " -0.07914953678846359,\n",
       " 0.017817426472902298,\n",
       " 0.0395965501666069,\n",
       " 0.036239635199308395,\n",
       " 0.012556263245642185,\n",
       " -0.050666097551584244,\n",
       " 0.057882554829120636,\n",
       " 0.06475129723548889,\n",
       " -0.0725456178188324,\n",
       " 0.03519894927740097,\n",
       " 0.030570028349757195,\n",
       " -0.006167229264974594,\n",
       " -0.011796296574175358,\n",
       " -0.008290175348520279,\n",
       " -0.017933540046215057,\n",
       " -0.04209362342953682,\n",
       " -0.012064228765666485,\n",
       " 0.00880552176386118,\n",
       " -0.05999321490526199,\n",
       " -0.03464368358254433,\n",
       " -0.08186905086040497,\n",
       " 0.0355706512928009,\n",
       " -0.04216013848781586,\n",
       " -0.10391668230295181,\n",
       " 0.0038084639236330986,\n",
       " -0.030506454408168793,\n",
       " 0.0399044007062912,\n",
       " 0.03539436310529709,\n",
       " -0.01851348765194416,\n",
       " -0.030506830662488937,\n",
       " 0.01296560000628233,\n",
       " 0.02962312288582325,\n",
       " -0.05594923719763756,\n",
       " 0.026137271896004677,\n",
       " 0.027979889884591103,\n",
       " -0.032783620059490204,\n",
       " -0.05861344188451767,\n",
       " 0.029305243864655495,\n",
       " 0.025631634518504143,\n",
       " 0.046621762216091156,\n",
       " -0.01578911766409874,\n",
       " -0.05855393409729004,\n",
       " -0.033567510545253754,\n",
       " -0.022099914029240608,\n",
       " 0.07099347561597824,\n",
       " -0.015482406131923199,\n",
       " -0.02221505530178547,\n",
       " 0.020550455898046494,\n",
       " 0.03193112462759018,\n",
       " 0.009649628773331642,\n",
       " 0.08112385869026184,\n",
       " 0.024486811831593513,\n",
       " -0.020967384800314903,\n",
       " -0.001703555346466601,\n",
       " 0.003984694369137287,\n",
       " 0.01214590948075056,\n",
       " 0.02251713164150715,\n",
       " 0.011797886341810226,\n",
       " -0.014598767273128033,\n",
       " -0.027774184942245483,\n",
       " 0.035769712179899216,\n",
       " -0.04636594280600548,\n",
       " 0.006575292441993952,\n",
       " 0.01091056503355503,\n",
       " 0.06001884862780571,\n",
       " -0.03792550787329674,\n",
       " 0.025552064180374146,\n",
       " -0.052944615483284,\n",
       " -0.00331985205411911,\n",
       " 0.04723644629120827,\n",
       " 0.04916655644774437,\n",
       " -0.012118092738091946,\n",
       " -0.015976974740624428,\n",
       " -0.023780548945069313,\n",
       " -0.020015906542539597,\n",
       " -0.016765648499131203,\n",
       " 0.017619017511606216,\n",
       " 0.09507094323635101,\n",
       " 0.02456720732152462,\n",
       " -0.00030371572938747704,\n",
       " 0.07726727426052094,\n",
       " 0.009286770597100258,\n",
       " 0.04579121246933937,\n",
       " 0.0006386045133695006,\n",
       " -0.0203663669526577,\n",
       " 0.05929982289671898,\n",
       " -0.009882405400276184,\n",
       " 0.017564021050930023,\n",
       " -0.05515163019299507,\n",
       " 0.016189292073249817,\n",
       " 0.028766026720404625,\n",
       " -0.03514404594898224,\n",
       " -0.04935841262340546,\n",
       " -0.02447367087006569,\n",
       " -0.02685004286468029,\n",
       " -0.009837007150053978,\n",
       " 9.710079029900953e-05,\n",
       " 0.019255781546235085,\n",
       " 0.016495689749717712,\n",
       " 0.019392136484384537,\n",
       " 0.014026164077222347,\n",
       " 0.044185783714056015,\n",
       " -0.0408172607421875,\n",
       " 0.058831170201301575,\n",
       " 0.033452264964580536,\n",
       " -0.07100701332092285,\n",
       " -0.01207928266376257,\n",
       " 0.017947617918252945,\n",
       " 0.026635218411684036,\n",
       " -0.042489077895879745,\n",
       " -0.025743063539266586,\n",
       " 0.04628248140215874,\n",
       " 0.02357054501771927,\n",
       " 0.012330091558396816,\n",
       " -0.019114600494503975,\n",
       " 0.04284172132611275,\n",
       " 0.020867055281996727,\n",
       " -0.020985012874007225,\n",
       " 0.049807094037532806,\n",
       " -0.06530244648456573,\n",
       " 0.06784137338399887,\n",
       " 0.06132720038294792,\n",
       " -0.025619087740778923,\n",
       " -0.01975896954536438,\n",
       " -0.028557993471622467,\n",
       " -0.0033664510119706392,\n",
       " -0.022265056148171425,\n",
       " 0.0277670007199049,\n",
       " 0.0376681424677372,\n",
       " -0.01844070851802826,\n",
       " -0.0666554793715477,\n",
       " -0.03576522693037987,\n",
       " -0.006980367470532656,\n",
       " -0.009456862695515156,\n",
       " 0.007616228424012661,\n",
       " -0.002117250580340624,\n",
       " -0.000508638215251267,\n",
       " -0.058485377579927444,\n",
       " 0.02196097932755947,\n",
       " 0.011461308225989342,\n",
       " -0.019124537706375122,\n",
       " 0.017011091113090515,\n",
       " -0.03894034028053284,\n",
       " -0.024677084758877754,\n",
       " -0.009032917208969593,\n",
       " 0.019948668777942657,\n",
       " -0.020086267963051796,\n",
       " 0.0046862466260790825,\n",
       " 0.0658910721540451,\n",
       " -0.021722840145230293,\n",
       " -0.0028560664504766464,\n",
       " 0.011400393210351467,\n",
       " -0.014010073617100716,\n",
       " -0.05337538197636604,\n",
       " -0.07439275830984116,\n",
       " 0.0002861053217202425,\n",
       " 0.04116436839103699,\n",
       " 0.03818747028708458,\n",
       " -0.012812647968530655,\n",
       " 0.05230933055281639,\n",
       " 0.018940966576337814,\n",
       " -0.048808012157678604,\n",
       " -0.06779120117425919,\n",
       " -0.01911095529794693,\n",
       " -0.028975164517760277,\n",
       " 0.004133264068514109,\n",
       " 0.01923450082540512,\n",
       " -0.020669246092438698,\n",
       " -0.003695683553814888,\n",
       " 0.009470553137362003,\n",
       " -0.041596852242946625,\n",
       " 0.045980364084243774,\n",
       " 0.029285280033946037,\n",
       " -0.07706877589225769,\n",
       " 0.006656208075582981,\n",
       " -0.005012008361518383,\n",
       " -0.017416084185242653,\n",
       " 0.007063459139317274,\n",
       " -0.05976015701889992,\n",
       " 0.0185412485152483,\n",
       " -0.0273988489061594,\n",
       " 0.005803277250379324,\n",
       " -0.041785452514886856,\n",
       " -0.0908936932682991,\n",
       " -0.006833197548985481,\n",
       " -0.014357824809849262,\n",
       " 0.08537802845239639,\n",
       " -0.05669703334569931,\n",
       " 0.06276111304759979,\n",
       " 0.0009012018563225865,\n",
       " -0.007769424468278885,\n",
       " -0.02144297957420349,\n",
       " -0.11318439245223999,\n",
       " 0.07541830092668533,\n",
       " 0.023151574656367302,\n",
       " 0.005866213236004114,\n",
       " -0.004821085371077061,\n",
       " -0.010738340206444263,\n",
       " 0.02703235298395157,\n",
       " 0.025599531829357147,\n",
       " 0.007024332880973816,\n",
       " -0.032584112137556076,\n",
       " -0.04185543581843376,\n",
       " -0.024687552824616432,\n",
       " -0.02051878534257412,\n",
       " -0.04894666746258736,\n",
       " 0.03619479760527611,\n",
       " -0.04281015321612358,\n",
       " 0.014844655990600586,\n",
       " 0.010251615196466446,\n",
       " 0.023320626467466354,\n",
       " 0.01871577650308609,\n",
       " 0.03378577157855034,\n",
       " -0.025527965277433395,\n",
       " 0.044417854398489,\n",
       " -0.02600604109466076,\n",
       " -0.0119530213996768,\n",
       " -0.055049628019332886,\n",
       " 0.022267477586865425,\n",
       " -0.010707407258450985,\n",
       " -0.026371469721198082,\n",
       " -0.009768350049853325,\n",
       " -0.01535708550363779,\n",
       " -0.019579773768782616,\n",
       " -0.021421188488602638,\n",
       " 0.006235864479094744,\n",
       " 0.0314040407538414,\n",
       " 0.031010085716843605,\n",
       " 0.004555661231279373,\n",
       " -0.031087100505828857,\n",
       " -0.014605932869017124,\n",
       " -0.003368874778971076,\n",
       " -0.028359955176711082,\n",
       " 0.057969674468040466,\n",
       " -0.09270115196704865,\n",
       " -0.009005305357277393,\n",
       " 0.022297324612736702,\n",
       " -0.02122938074171543,\n",
       " -0.03563996031880379,\n",
       " 0.004106925334781408,\n",
       " 0.006597382482141256,\n",
       " 0.03264277055859566,\n",
       " 0.03904365748167038,\n",
       " 0.02032073214650154,\n",
       " 0.005939505994319916,\n",
       " 0.010560653172433376,\n",
       " -0.002243859926238656,\n",
       " 0.02130184881389141,\n",
       " -0.02763022854924202,\n",
       " 0.014897515065968037,\n",
       " -0.020667249336838722,\n",
       " -0.09472247958183289,\n",
       " -0.0004307603812776506,\n",
       " -0.02479407750070095,\n",
       " 0.028932971879839897,\n",
       " 0.025980545207858086,\n",
       " 0.057643499225378036,\n",
       " -0.0374685563147068,\n",
       " 0.0006257054628804326,\n",
       " -0.01778700202703476,\n",
       " 0.017848286777734756,\n",
       " -0.00700916163623333,\n",
       " -0.026394061744213104,\n",
       " 0.03204090893268585,\n",
       " -0.005773015785962343,\n",
       " -0.012837935239076614,\n",
       " 0.016041608527302742,\n",
       " 0.030365966260433197,\n",
       " -0.025132445618510246,\n",
       " 0.0380871519446373,\n",
       " 0.026565272361040115,\n",
       " 0.061460208147764206,\n",
       " 0.018262824043631554,\n",
       " -0.025590986013412476,\n",
       " -0.014801396057009697,\n",
       " -0.009373162873089314,\n",
       " -0.05065552145242691,\n",
       " -0.01938270404934883,\n",
       " 0.04338742420077324,\n",
       " -0.008704069070518017,\n",
       " 0.020551657304167747,\n",
       " 0.010078946128487587,\n",
       " -0.022332625463604927,\n",
       " 0.013624574989080429,\n",
       " -0.029078511521220207,\n",
       " -0.02031247317790985,\n",
       " 0.04527844116091728,\n",
       " 0.008548842743039131,\n",
       " -0.044655926525592804,\n",
       " -0.04993825778365135,\n",
       " -0.0005616651615127921,\n",
       " -0.0019093779847025871,\n",
       " 0.029475873336195946,\n",
       " 0.08492345362901688,\n",
       " 0.02737259492278099,\n",
       " -0.019202347844839096,\n",
       " -0.011180019937455654,\n",
       " 0.0613800473511219,\n",
       " 0.0009942551841959357,\n",
       " -0.005685679614543915,\n",
       " 0.010302840732038021,\n",
       " 0.0048909238539636135,\n",
       " 0.03689644858241081,\n",
       " 6.452776142396033e-05,\n",
       " -0.02497044950723648,\n",
       " 0.006457015406340361,\n",
       " -0.03664189949631691,\n",
       " -0.03386320546269417,\n",
       " -0.009320611134171486,\n",
       " 0.027527937665581703,\n",
       " -0.006957217585295439,\n",
       " -0.0016937933396548033,\n",
       " 0.02136092633008957,\n",
       " 0.008775141090154648,\n",
       " 0.031389400362968445,\n",
       " 0.05911479890346527,\n",
       " 0.10196645557880402,\n",
       " 0.03833167254924774,\n",
       " 0.059265561401844025,\n",
       " -0.034477267414331436,\n",
       " 0.01983230747282505,\n",
       " -0.028979182243347168,\n",
       " -0.0006717467331327498,\n",
       " 0.023720132187008858,\n",
       " 0.009949897415935993,\n",
       " -0.027036644518375397,\n",
       " -0.02788533642888069,\n",
       " -0.009638091549277306,\n",
       " -0.017497442662715912,\n",
       " 0.05965723469853401,\n",
       " -0.023421915248036385,\n",
       " -7.17904549674131e-05,\n",
       " -0.023910334333777428,\n",
       " 0.010167197324335575,\n",
       " 0.06294538080692291,\n",
       " -0.007855839096009731,\n",
       " 0.009582506492733955,\n",
       " -0.00771779241040349,\n",
       " 0.010753695853054523,\n",
       " 0.029988912865519524,\n",
       " -0.0410747155547142,\n",
       " 0.014009366743266582,\n",
       " -0.016409873962402344,\n",
       " -0.025754181668162346,\n",
       " -0.029275324195623398,\n",
       " 0.06891670823097229,\n",
       " 0.00874270685017109,\n",
       " 0.023196490481495857,\n",
       " -0.038228556513786316,\n",
       " 0.016259821131825447,\n",
       " -0.013566256500780582,\n",
       " 0.025782182812690735,\n",
       " -0.020683975890278816,\n",
       " 0.04356987029314041,\n",
       " 0.03843095898628235,\n",
       " 0.011759771965444088,\n",
       " 0.0006424587918445468,\n",
       " 0.06934863328933716,\n",
       " 0.004451766610145569,\n",
       " 0.05257083848118782,\n",
       " 0.05299004167318344,\n",
       " -0.027428876608610153,\n",
       " 0.007362625561654568,\n",
       " -0.027196450158953667,\n",
       " -0.03716901317238808,\n",
       " -0.05996355041861534,\n",
       " -0.018047159537672997,\n",
       " 0.010596984066069126,\n",
       " -0.019895626232028008,\n",
       " -0.02837696112692356,\n",
       " -0.02666792832314968,\n",
       " 0.005059539806097746,\n",
       " -0.00711184972897172,\n",
       " 0.028563370928168297,\n",
       " 0.10317031294107437,\n",
       " 0.04524599015712738,\n",
       " -0.09671919792890549,\n",
       " -0.05298631638288498,\n",
       " -0.02709105610847473,\n",
       " -0.03117411397397518,\n",
       " -0.010037784464657307,\n",
       " 0.0028370970394462347,\n",
       " -0.01989951729774475,\n",
       " 0.054531022906303406,\n",
       " 0.017425885424017906,\n",
       " -0.031392212957143784,\n",
       " -0.0492844320833683,\n",
       " 0.012391205877065659,\n",
       " 0.021212412044405937,\n",
       " -0.010904794558882713,\n",
       " -0.02079067938029766,\n",
       " 0.010785725899040699,\n",
       " 0.0042291851714253426,\n",
       " 0.007526397705078125,\n",
       " 0.018077723681926727,\n",
       " -0.030186735093593597,\n",
       " -0.06504229456186295,\n",
       " -0.0060129123739898205,\n",
       " 0.04470229893922806,\n",
       " -0.0001683917362242937,\n",
       " 0.014180039055645466,\n",
       " 0.02072112262248993,\n",
       " 0.001374627579934895,\n",
       " 0.03986472263932228,\n",
       " 0.02338232658803463,\n",
       " 0.0028986725956201553,\n",
       " 0.018854621797800064,\n",
       " 0.018174119293689728,\n",
       " 0.008018970489501953,\n",
       " -0.001832504291087389,\n",
       " 0.004592920653522015,\n",
       " -0.01788954995572567,\n",
       " 0.004617960192263126,\n",
       " -0.028025709092617035,\n",
       " 0.04705401882529259,\n",
       " 0.027661263942718506,\n",
       " 0.0065150074660778046,\n",
       " -0.030028309673070908,\n",
       " -0.05390259250998497,\n",
       " -0.0013852387201040983,\n",
       " -0.01643216609954834,\n",
       " -0.06801334023475647,\n",
       " 0.05069683864712715,\n",
       " 0.06540688872337341,\n",
       " 0.01848502829670906,\n",
       " 0.03506237268447876,\n",
       " 0.015128708444535732,\n",
       " -0.0009853191440925002,\n",
       " 0.018667006865143776,\n",
       " -0.02371547929942608,\n",
       " -0.03277934715151787,\n",
       " -0.04126175865530968,\n",
       " 0.0004407509695738554,\n",
       " -0.006913974415510893,\n",
       " 0.001071878825314343,\n",
       " 0.04121888801455498,\n",
       " 0.033742137253284454,\n",
       " 0.06251147389411926,\n",
       " 0.07336639612913132,\n",
       " 0.036337900906801224,\n",
       " -0.020660797134041786,\n",
       " -0.023938000202178955,\n",
       " 0.02654903009533882,\n",
       " -0.009692799299955368,\n",
       " -0.04504105821251869,\n",
       " 0.022294068709015846,\n",
       " 0.03183344379067421,\n",
       " -0.013615928590297699,\n",
       " 0.09686916321516037,\n",
       " 0.05850844457745552,\n",
       " 0.05051637440919876,\n",
       " 0.06556273996829987,\n",
       " -0.030124453827738762,\n",
       " -0.05741645395755768,\n",
       " 0.08546410501003265,\n",
       " -0.09430325776338577,\n",
       " -0.0328102707862854,\n",
       " -0.026789216324687004,\n",
       " 0.03717803210020065,\n",
       " 0.08715295791625977,\n",
       " 0.0001604699791641906,\n",
       " -0.009505724534392357,\n",
       " -0.01792062073945999,\n",
       " 0.008379129692912102,\n",
       " 0.0796549916267395,\n",
       " 0.033412281423807144,\n",
       " 0.04523250833153725,\n",
       " 0.002415842143818736,\n",
       " -0.08875352889299393,\n",
       " -0.02112312614917755,\n",
       " 0.034831877797842026,\n",
       " 0.008336428552865982,\n",
       " 0.03964807465672493,\n",
       " 0.022455615922808647,\n",
       " 0.010564827360212803,\n",
       " -0.02183358184993267,\n",
       " -0.03671906143426895,\n",
       " 0.016374699771404266,\n",
       " -0.07664699852466583,\n",
       " -0.04381590336561203,\n",
       " 0.008805062621831894,\n",
       " -0.029425987973809242,\n",
       " 0.035350218415260315,\n",
       " 0.03271523490548134,\n",
       " -0.008388573303818703,\n",
       " -0.021349893882870674,\n",
       " 0.01584000512957573,\n",
       " -0.014425228349864483,\n",
       " -0.001280902768485248,\n",
       " -0.015345528721809387,\n",
       " -0.05014083534479141,\n",
       " 0.004639973398298025,\n",
       " 0.00799761712551117,\n",
       " 0.01279925275593996,\n",
       " 0.01869218423962593,\n",
       " 0.050975508987903595,\n",
       " -0.004513971973210573]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ae86b",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8dcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8feb528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68999868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32486a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0253c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=os.path.join(os.getcwd(), \"data\", \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9d58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2ae1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376cb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6670c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc6e89",
   "metadata": {},
   "source": [
    "### this is a experimental thing there is no deterministic way to split the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e5f06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "361efa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53ed226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f15a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 0, 'page_label': '1'}, page_content='Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72cddd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce96aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96181a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "0,1,2,3\n",
    "page_lable=4\n",
    "actual page is 4 \n",
    "\n",
    "page_index=3\n",
    "page_lable=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "865ed5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 3,\n",
       " 'page_label': '4'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[100].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fd5afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 7,\n",
       " 'page_label': '8'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[200].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec192b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f92af725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ded599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6835d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector=embedding_model.embed_documents(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c109387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_documents(docs[0].page_content)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed952e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "token->words\n",
    "\n",
    "chunk--> it is collection of words(token)[characters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e769025",
   "metadata": {},
   "source": [
    "1. in memory(faiss is in memory vector store,chroma)\n",
    "2. on disk storage(faiss you can persist over the disk,chroma)\n",
    "3. cloud storage(cloud variant of faiss is not available)(pinecone,weaviate,milvus,mongodbvectorsearch,astradb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd5d79",
   "metadata": {},
   "source": [
    "## This is a Retrieval proceesss\n",
    "\n",
    "means from the vectordatabase we are going to fetch or retrive or rank the most appropriate k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55503be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da52627f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6289bcec-31dc-48ff-84fa-d69a9655495a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='this paper contributes a thorough description of our fine-tuning methodology and approach to improving'),\n",
       " Document(id='75b176ce-4658-4ef0-bc85-b05445f93f3a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='any publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety'),\n",
       " Document(id='b2cb4a7c-7366-4888-946e-f8605b6af2e7', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='benchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='b8c2d93b-c55c-403b-b51e-4696affef8df', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='partially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2onthreepopular')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b59e667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this paper contributes a thorough description of our fine-tuning methodology and approach to improving'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d2f345b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'any publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c52e60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'benchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01f6ff55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'partially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2onthreepopular'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a971b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b687780f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6289bcec-31dc-48ff-84fa-d69a9655495a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='this paper contributes a thorough description of our fine-tuning methodology and approach to improving'),\n",
       " Document(id='75b176ce-4658-4ef0-bc85-b05445f93f3a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='any publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety'),\n",
       " Document(id='b2cb4a7c-7366-4888-946e-f8605b6af2e7', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='benchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='b8c2d93b-c55c-403b-b51e-4696affef8df', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='partially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2onthreepopular'),\n",
       " Document(id='e097e958-0e22-4803-b47b-38152106b6a3', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='descriptions of the benchmarks and metrics can be found in Appendix A.4.7. When compared toLlama 1-7B,'),\n",
       " Document(id='26d11b87-ba5c-4d85-94d2-d1f760888cf1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 35, 'page_label': '36'}, page_content='7 Conclusion\\nIn this study, we have introducedLlama 2, a new family of pretrained and fine-tuned models with scales'),\n",
       " Document(id='65017910-5871-45e1-9160-df168297aaef', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8'),\n",
       " Document(id='f7ab7e0c-a6c1-4798-890a-68f44d762a37', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 18, 'page_label': '19'}, page_content='tasks. There are relatively few public benchmarks for these contexts, so we feel sharing our analysis here will\\nbenefit the research community.'),\n",
       " Document(id='aee4b7f8-6afe-4c48-9ffc-c44ef6b589a1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 47, 'page_label': '48'}, page_content='2 models and others open-source models.\\nStandard Benchmarks. In Table 20, we show results on several standard benchmarks.'),\n",
       " Document(id='0d36328d-dc33-4c31-8495-9aed39b01929', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 12, 'page_label': '13'}, page_content='models obtain higher performance for a similar volume of data. More importantly, the scaling performance')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67ff01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2c9f69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6289bcec-31dc-48ff-84fa-d69a9655495a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='this paper contributes a thorough description of our fine-tuning methodology and approach to improving')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8481a",
   "metadata": {},
   "source": [
    "### you can explore about keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2df7b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d5f07ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6289bcec-31dc-48ff-84fa-d69a9655495a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='this paper contributes a thorough description of our fine-tuning methodology and approach to improving'),\n",
       " Document(id='75b176ce-4658-4ef0-bc85-b05445f93f3a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='any publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety'),\n",
       " Document(id='b2cb4a7c-7366-4888-946e-f8605b6af2e7', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='benchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='b8c2d93b-c55c-403b-b51e-4696affef8df', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='partially made up of programming code data.\\nSafetyBenchmarksforPretrainedModels. Weevaluatethesafetycapabilitiesof Llama 2onthreepopular'),\n",
       " Document(id='e097e958-0e22-4803-b47b-38152106b6a3', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 21, 'page_label': '22'}, page_content='descriptions of the benchmarks and metrics can be found in Appendix A.4.7. When compared toLlama 1-7B,'),\n",
       " Document(id='26d11b87-ba5c-4d85-94d2-d1f760888cf1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 35, 'page_label': '36'}, page_content='7 Conclusion\\nIn this study, we have introducedLlama 2, a new family of pretrained and fine-tuned models with scales'),\n",
       " Document(id='65017910-5871-45e1-9160-df168297aaef', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8'),\n",
       " Document(id='f7ab7e0c-a6c1-4798-890a-68f44d762a37', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 18, 'page_label': '19'}, page_content='tasks. There are relatively few public benchmarks for these contexts, so we feel sharing our analysis here will\\nbenefit the research community.'),\n",
       " Document(id='aee4b7f8-6afe-4c48-9ffc-c44ef6b589a1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 47, 'page_label': '48'}, page_content='2 models and others open-source models.\\nStandard Benchmarks. In Table 20, we show results on several standard benchmarks.'),\n",
       " Document(id='0d36328d-dc33-4c31-8495-9aed39b01929', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sunny\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 12, 'page_label': '13'}, page_content='models obtain higher performance for a similar volume of data. More importantly, the scaling performance')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a2e3a",
   "metadata": {},
   "source": [
    "## Question: user question\n",
    "## Context: based on the question retrieving the info from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32650c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provided below. \n",
    "        If the context does not contain sufficient information, respond with: \n",
    "        \"I do not have enough information about this.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9189656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ccc6ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82058939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45dc8fe",
   "metadata": {},
   "source": [
    "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5b39444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f17d8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ef826e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fbcf20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b10cb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0c3976d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to answer the question about the Llama 2 fine-tuning benchmark experiments based on the provided context. Let me read through the context carefully to extract relevant information.\\n\\nFirst, the context mentions Table 3, which summarizes the overall performance across various benchmarks. It refers to Appendix A.4.7 for safety descriptions and metrics. However, the main details about the experiments are in Section 3, which covers fine-tuning. \\n\\nIn Section 3, the context talks about using supervised fine-tuning, including both instruction tuning and RLHF (Reinforcement Learning with Human Feedback). It mentions that these methods required significant computational and annotation resources. There's a reference to InstructionTuning by Weietal. (2021), which achieved zero-shot performance on unseen tasks by fine-tuning LLMs.\\n\\nThe context also points out that Section A.2.2 has results for individual benchmarks, but since that's not provided here, I can't access those specific details. \\n\\nSo, putting it together, the answer should mention that Llama 2's fine-tuning involved supervised methods like instruction tuning and RLHF, required substantial resources, and refers to Weietal.'s work. Since detailed benchmark results are in a section not provided, I should note that individual results are available elsewhere but not here.\\n</think>\\n\\nThe Llama 2 fine-tuning benchmark experiments involved supervised fine-tuning methods, including instruction tuning and RLHF (Reinforcement Learning with Human Feedback). These approaches required significant computational and annotation resources. The experiments built on work by Weietal. (2021), which achieved zero-shot performance on unseen tasks through fine-tuning. While detailed benchmark results are available in Section A.2.2, this specific information is not provided in the given context.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell  me about the llama2 finetuning benchmark experiments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca813139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out the scaling trends for the reward model based on the provided context. Let me read through the context carefully.\\n\\nFirst, the context mentions that Figure 6 shows scaling trends for the reward model. It says that more data and a larger model size generally improve accuracy. It also notes that the models haven't yet saturated from the training data, which means there's still room for improvement.\\n\\nLooking further, there's a mention of tuning different model sizes on increasing amounts of reward model data collected each week. The answers are based on a 7-point Likert scale, where higher is better. The reward models overall perform better on more distinct responses than similar pairs.\\n\\nThere's also a section on scaling trends in terms of data and model size for the reward model, both fine-tuned and on-distribution. It talks about maintaining accurate rewards for the latest model. Table 6 presents statistics of reward modeling data collected over time, showing how the models predict a scalar for a single output without requiring retraining each time. \\n\\nAdditionally, it's noted that reward model accuracy is one of the most important factors and that there's still room for improvement with more annotations. The reward models can predict accurately, but there's potential for more enhancement as the data and model size increase.\\n\\nSo, putting this all together, the scaling trends indicate that as more data is added and the model size increases, the reward model's accuracy improves. The models haven't reached their limit yet, so further scaling should continue to enhance performance.\\n</think>\\n\\nThe scaling trends for the reward model, as shown in Figure 6, indicate that both an increase in data and a larger model size lead to improved accuracy. The models have not yet reached their learning saturation point, suggesting that there is still potential for further improvement with additional data and model scaling. The reward models perform better on more distinct responses compared to similar pairs, and they maintain accurate rewards for the latest models. Overall, the trends highlight the positive impact of scaling on reward model performance.\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"can you tell me Scaling trends for the reward model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826f5b4",
   "metadata": {},
   "source": [
    "# One Small task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26672a6a",
   "metadata": {},
   "source": [
    "### Take 10 pdfs keep it in same directory and create RAG on top of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1345b",
   "metadata": {},
   "source": [
    "In next class will discuss about the(will start with the modular coding)\n",
    "1. exception module\n",
    "2. logger module\n",
    "3. doc analyser\n",
    "4. doc compare\n",
    "5. utils and config\n",
    "   \n",
    "2 class\n",
    "\n",
    "2 more class api and other module\n",
    "\n",
    "2 more class for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1a8f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
